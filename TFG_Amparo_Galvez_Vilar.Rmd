---
title: "Procedimiento y análisis de datos"
author: "Amparo Galvez Vilar"
date: "2025-02-20"
output:
  html_document: 
    toc: true         
    toc_depth: 2
    number_sections: true
  pdf_document: 
    toc: true         
    toc_depth: 2
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  warning = FALSE,
  message = FALSE
)
```

# CARGA DE LIBRERÍAS
```{r}
library(car)
library(dplyr)
library(emmeans)
library(GGally)
library(gmodels)
library(grid)
library(lavaan)
library(likert)
library(pROC)
library(psych)
library(RColorBrewer)
library(readr)
library(reshape2)
library(ResourceSelection)
library(scales)
library(semTools)
library(tibble)
library(tidyverse)
```

# CARGA DE DATOS E INSPECCION INICIAL

```{r}
df <- read_delim("~/uni/CUARTO/segundi_cuatri/TFG/data/Datos_Amparo_FINAL_COPIA.csv", 
    delim = ";", escape_double = FALSE, trim_ws = TRUE)
```

```{r}
glimpse(df)   # Muestra tipos de cada columna y primeros valores
summary(df)   # Estadísticos básicos de cada variable
```

# RECODIFICAR LAS VARIABLES

```{r}
df <- df %>%
  # 1. Recodificar variables de entorno y chequeos
  mutate(
    S2    = factor(S2,
                       levels = c(1, 2),
                       labels = c("Masculino", "Femenino")),
    CuotaEdad = factor(CUOTA_EDAD,
                       levels = c(1, 2, 3),
                       labels = c("18–30", "31–50", "51–65")),
    TamPob    = factor(S3,
                       levels = 1:8,
                       labels = c("<5.000", "5.001–10.000", "10.001–25.000",
                                  "25.001–50.000", "50.001–100.000",
                                  "100.001–500.000", ">500.000", "Desconocido")),
    Escenario = factor(ESCENARIO,
                       levels = 1:4,
                       labels = c("BajaConf+Auto", "AltaConf+Auto",
                                  "BajaConf+Asist", "AltaConf+Asist")),
    CompraBin = factor(P3,
                       levels = c(1, 2),
                       labels = c("Tienda", "Online")),
    CheckConf = factor(P5_1,
                       levels = c(1, 2),
                       labels = c("PercibióAltaConf", "PercibióBajaConf")),
    CheckServ = factor(P5_2,
                       levels = c(1, 2),
                       labels = c("PercibióAsist", "PercibióAuto"))
  ) %>%
  # 2. Crear variables derivadas para el análisis
  mutate(
    CONFIANZA = if_else(ESCENARIO %in% c(1, 3), 1, 2),  # 1=Baja, 2=Alta
    SERVICIO  = if_else(ESCENARIO %in% c(1, 2), 1, 2),   # 1=Auto, 2=Asistido
    
    # Showrooming: 1 = visitó tienda y compró online, 0 = compró en tienda
    SHOWROOMING = if_else(P3 == 2, 1, 0)
  ) %>%
  # 3. Convertir las nuevas variables en factores con etiquetas
  mutate(
    CONFIANZA   = factor(CONFIANZA,
                         levels = c(1, 2),
                         labels = c("BajaConfianza", "AltaConfianza")),
    SERVICIO    = factor(SERVICIO,
                         levels = c(1, 2),
                         labels = c("Autoservicio", "Asistido")),
    SHOWROOMING = factor(SHOWROOMING,
                         levels = c(0, 1),
                         labels = c("No", "Sí"))
  )

```

# LIMPIEZA DE DATOS

```{r}
# Calcular % de NA en las escalas principales y P3_2
vars_na <- c(paste0("P6_", 1:3),
             paste0("P7_", 1:4),
             paste0("P8_", 1:3)
             )

df <- df %>%
  rowwise() %>%
  mutate(pct_na = sum(is.na(c_across(all_of(vars_na)))) / length(vars_na)) %>%
  ungroup()

# Resumen de pct_na
summary(df$pct_na)
table(cut(df$pct_na, breaks = c(-Inf, 0, .1, 1), labels = c("0%", "0-10%", ">10%")))

```

```{r}
# Filtrar
df_step2 <- df %>% filter(pct_na <= 0.10)
cat("Casos tras filtrar >10% NA:", nrow(df_step2), 
    " (se eliminaron", nrow(df) - nrow(df_step2), "casos)\n")

```

```{r}
# Función para imputar media por variable
imputar_media <- function(x) ifelse(is.na(x), mean(x, na.rm = TRUE), x)

df_step3 <- df_step2

for (v in vars_na) {
  mean_v <- mean(df_step3[[v]], na.rm = TRUE)
  df_step3[[v]] <- imputar_media(df_step3[[v]])
  cat("Imputada media en", v, ":", round(mean_v,2), "\n")
}
```

```{r}
# Marcar qué filas tienen outliers en cada escala
outlier_flag <- function(x) {
  q <- quantile(x, c(.25, .75))
  iqr <- diff(q)
  x < (q[1] - 1.5 * iqr) | x > (q[2] + 1.5 * iqr)
}

# Para cada participante, contar en cuántas escalas es outlier
df_step3 <- df_step3 %>%
  rowwise() %>%
  mutate(
    n_outliers = sum(sapply(across(all_of(vars_na)), outlier_flag))
  ) %>%
  ungroup()

table(df_step3$n_outliers)

```

```{r}
df_clean <- df_step3 %>% filter(n_outliers <= 2)
cat("Casos tras eliminar >2 outliers:", nrow(df_clean),
    " (se eliminaron", nrow(df_step3) - nrow(df_clean), "casos)\n")

```
```{r}
df_summary <- tibble(
  Etapa   = c("Inicial", "Tras NA", "Tras Outliers"),
  Casos   = c(nrow(df), nrow(df_step2), nrow(df_clean))
)

ggplot(df_summary, aes(x = Etapa, y = Casos)) +
  geom_col(color = "black", alpha = 0.8) +
  geom_text(aes(label = Casos), vjust = -0.5) +
  labs(
    x = "Etapa del proceso de limpieza",
    y = "Número de casos",
    title = "Evolución del tamaño de la muestra tras limpieza e imputación"
  ) +
  theme_minimal()

```
# ESTADÍSTICOS DESCRIPTIVOS DE LA MUESTRA
```{r}
df_unicos <- df %>%
  distinct(REGISTRO, .keep_all = TRUE)
```
## Distribución variables sociodemográficas
### Género
```{r}
# GÉNERO
ggplot(df_unicos, aes(x = factor(S2, labels = c("Hombre","Mujer")))) +
  geom_bar(color = "black", alpha = 0.8) +
  labs(x = "Género", y = "Número de participantes",
       title = "Distribución por género") +
  theme_minimal()
```
### Edad
```{r}
# Estadísticos descriptivos de AGE
edad_stats <- df_unicos %>%
  summarise(
    media               = mean(AGE, na.rm = TRUE),
    mediana             = median(AGE, na.rm = TRUE),
    desviacion_tipica   = sd(AGE, na.rm = TRUE),
    varianza            = var(AGE, na.rm = TRUE),
    min                 = min(AGE, na.rm = TRUE),
    max                 = max(AGE, na.rm = TRUE),
  )
edad_stats

# 1. Histograma y boxplot de AGE
p_hist <- ggplot(df_unicos, aes(x = AGE)) +
  geom_histogram(binwidth = 5, color = "black", alpha = 0.8) +
  labs(x = "Edad (años)", y = "Frecuencia",
       title = "Histograma de edad") +
  theme_minimal()

p_box <- ggplot(df_unicos, aes(x = AGE)) +
  geom_boxplot(width = 0.3, color = "black", alpha = 0.8) +
  labs(x = "Edad (años)",
       title = "Boxplot de edad") +
  theme_minimal()
print(p_hist)
print(p_box)

# 2. Gráfico de barras de cuotas de edad
cuota_stats <- df_unicos %>%
  count(CUOTA_EDAD) %>%
  mutate(
    pct = n / sum(n) * 100,
    grupo = case_when(
      CUOTA_EDAD == 1 ~ "18–30",
      CUOTA_EDAD == 2 ~ "31–50",
      CUOTA_EDAD == 3 ~ "51–65"
    )
  )

p_bar <- ggplot(cuota_stats, aes(x = CUOTA_EDAD, y = pct)) +
  geom_col(color = "black", alpha = 0.8) +
  geom_text(aes(label = sprintf("%1.1f%%", pct)),
            vjust = -0.5) +
  labs(x = "Grupo de edad", y = "Porcentaje",
       title = "Distribución por franjas de edad") +
  theme_minimal()

print(p_bar)
```

### Tamaño municipio

```{r}
# 1. Calcular frecuencias y porcentajes para todas las categorías de S3
pob_stats <- df_unicos %>%
  count(S3) %>%
  mutate(
    grupo = case_when(
      S3 == 1 ~ "Menos de 5 000",
      S3 == 2 ~ "5 001–10 000",
      S3 == 3 ~ "10 001–25 000",
      S3 == 4 ~ "25 001–50 000",
      S3 == 5 ~ "50 001–100 000",
      S3 == 6 ~ "100 001–500 000",
      S3 == 7 ~ "Más de 500 000",
      S3 == 8 ~ "Desconozco"
    ),
    pct = n / sum(n) * 100
  )
print(pob_stats)

# 3. Gráfico de barras para todas las categorías
ggplot(pob_stats, aes(x = grupo, y = pct)) +
  geom_col(color = "black", alpha = 0.8) +
  geom_text(aes(label = sprintf("%1.1f%%", pct)),
            vjust = -0.5)+
  labs(
    x = "Tamaño del municipio",
    y = "Porcentaje de participantes",
    title = "Distribución según tamaño de población"
  ) +
  theme_minimal() 
```

## Equilibrio Escenario
```{r}
df_clean %>% group_by(ESCENARIO) %>% count()
```

## Tasa global Showrooming
```{r}
# 1. Calcular frec. y % de showrooming
show_stats <- df_clean %>% 
  count(SHOWROOMING) %>%
  mutate(
    pct = n / sum(n) * 100,
    etiqueta = if_else(SHOWROOMING == "Sí", "Sí showrooming", "No showrooming")
  )

# 2. Graficar
ggplot(show_stats, aes(x = etiqueta, y = pct)) +
  geom_col(color = "black", alpha = 0.8) +
  geom_text(aes(label = sprintf("%1.1f%%", pct)),
            vjust = -0.5) +
  labs(
    x = NULL,
    y = "Porcentaje de registros",
    title = "Proporción de registros con showrooming"
  ) +
  theme_minimal(base_size = 12)
```
### Distribución showrooming según variables sociodemográficas
```{r}
# 1) calculamos N y peso de cada género
peso_genero <- df_unicos %>%
  count(S2) %>%
  rename(N_gen = n) %>%
  mutate(w_gen = N_gen / sum(N_gen))

# 2) calculamos % showrooming dentro de cada género
pct_genero <- df_unicos %>%
  count(S2, SHOWROOMING) %>%
  group_by(S2) %>%
  mutate(pct = n / sum(n) * 100) %>%
  ungroup() %>%
  left_join(peso_genero, by = "S2")

# 3) graficamos, usando width = w_gen en geom_col
ggplot(pct_genero, aes(x = S2, y = pct, fill = SHOWROOMING, width = w_gen)) +
  geom_col(color = "black", alpha = 0.8, position = "stack") +
  geom_text(aes(label = sprintf("%1.0f%%\n(n=%d)", pct, n)),
            position = position_stack(vjust = 0.5), size = 3) +
  scale_y_continuous(expand = c(0, 0)) +
  scale_fill_manual(values = c("No" = "#d31919", "Sí" = "#48b150")) +
  labs(
    x     = "Género",
    y     = "Porcentaje dentro del género",
    fill  = "Showrooming",
    title = "Showrooming por género (anchura proporcional al tamaño muestral)"
  ) +
  theme_minimal()

```

```{r}
# Edad
# 1) Calculamos N y peso de cada grupo de edad
peso_edad <- df_unicos %>%
  count(CuotaEdad) %>%
  rename(N_edad = n) %>%
  mutate(w_edad = N_edad / sum(N_edad))

# 2) Calculamos % showrooming dentro de cada grupo de edad
pct_edad <- df_unicos %>%
  count(CuotaEdad, SHOWROOMING) %>%
  group_by(CuotaEdad) %>%
  mutate(pct = n / sum(n) * 100) %>%
  ungroup() %>%
  left_join(peso_edad, by = "CuotaEdad")

# 3) Graficamos: barras apiladas cuya anchura es proporcional al tamaño muestral
ggplot(pct_edad, aes(x = CuotaEdad, y = pct, fill = SHOWROOMING, width = w_edad)) +
  geom_col(position = "stack", color = "black", alpha = 0.8) +
  geom_text(aes(label = sprintf("%1.0f%%\n(n=%d)", pct, n)),
            position = position_stack(vjust = 0.5), size = 3) +
  scale_y_continuous(expand = c(0, 0)) +
  scale_fill_manual(values = c("No" = "#d31919", "Sí" = "#48b150")) +
  labs(
    x     = "Grupo de edad",
    y     = "Porcentaje dentro del grupo",
    fill  = "Showrooming",
    title = "Showrooming por grupo de edad\n(anchura proporcional al tamaño de muestra)"
  ) +
  theme_minimal()

```
```{r}
# 1) Calculamos N y peso de cada categoría de tamaño de municipio
peso_pob <- df_unicos %>%
  count(TamPob) %>%
  rename(N_pob = n) %>%
  mutate(w_pob = N_pob / sum(N_pob))

# 2) Calculamos % showrooming dentro de cada categoría
pct_pob <- df_unicos %>%
  count(TamPob, SHOWROOMING) %>%
  group_by(TamPob) %>%
  mutate(pct = n / sum(n) * 100) %>%
  ungroup() %>%
  left_join(peso_pob, by = "TamPob")

# 3) Graficamos: barras apiladas cuya anchura (width) es w_pob
ggplot(pct_pob, aes(x = TamPob, y = pct, fill = SHOWROOMING, width = w_pob)) +
  geom_col(position = "stack", color = "black", alpha = 0.8) +
  geom_text(aes(label = sprintf("%1.0f%%\n(n=%d)", pct, n)),
            position = position_stack(vjust = 0.5), size = 3) +
  scale_y_continuous(expand = c(0, 0)) +
  scale_fill_manual(values = c("No" = "#d31919", "Sí" = "#48b150")) +
  labs(
    x     = "Tamaño de municipio",
    y     = "Porcentaje dentro de la categoría",
    fill  = "Showrooming",
    title = "Showrooming por tamaño de municipio\n(anchura proporcional al tamaño muestral)"
  ) +
  theme_minimal() 

```

```{r}
# 1) Peso de cada combinación Género x Edad
peso_ge <- df_unicos %>%
  count(S2, CuotaEdad) %>%
  rename(N_ge = n) %>%
  mutate(w_ge = N_ge / sum(N_ge))

# 2) % showrooming dentro de cada combinación
pct_ge <- df_unicos %>%
  count(S2, CuotaEdad, SHOWROOMING) %>%
  group_by(S2, CuotaEdad) %>%
  mutate(pct = n / sum(n) * 100) %>%
  ungroup() %>%
  left_join(peso_ge, by = c("S2", "CuotaEdad"))

# 3) Gráfico
ggplot(pct_ge, aes(x = interaction(CuotaEdad, S2, sep = " \n"), 
                   y = pct, 
                   fill = SHOWROOMING, 
                   width = w_ge)) +
  geom_col(position = "stack", color = "black", alpha = 0.8) +
  geom_text(aes(label = sprintf("%1.0f%%\n(n=%d)", pct, n)),
            position = position_stack(vjust = 0.5), size = 3) +
  scale_y_continuous(expand = c(0, 0)) +
  scale_fill_manual(values = c("No" = "#d31919", "Sí" = "#48b150")) +
  labs(
    x     = "Grupo de edad y Género",
    y     = "Porcentaje dentro de cada celda",
    fill  = "Showrooming",
    title = "Distribución de showrooming por combinación Edad x Género\n(anchura proporcional al tamaño muestral)"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(hjust = 0.5),
    panel.grid.major.x = element_blank()
  )

```

```{r}
# 1) Peso de cada combinación GéneroxEdadxMunicipio
peso_tripleta <- df_clean %>%
  count(S2, CuotaEdad, TamPob) %>%
  rename(N_trip = n) %>%
  mutate(w_trip = N_trip / sum(N_trip))

# 2) % showrooming dentro de cada combinación
pct_tripleta <- df_clean %>%
  count(S2, CuotaEdad, TamPob, SHOWROOMING) %>%
  group_by(S2, CuotaEdad, TamPob) %>%
  mutate(pct = n / sum(n) * 100) %>%
  ungroup() %>%
  left_join(peso_tripleta, by = c("S2", "CuotaEdad", "TamPob"))

# 3) Gráfico con facet_grid Género vs Edad
ggplot(pct_tripleta,
       aes(x = TamPob, 
           y = pct, 
           fill = SHOWROOMING, 
           width = w_trip)) +
  geom_col(position = "stack", color = "black", alpha = 0.8) +
  geom_text(aes(label = sprintf("%1.0f%%\n(n=%d)", pct, n)),
            position = position_stack(vjust = 0.5),
            size = 2.5) +
  facet_grid(rows = vars(S2), cols = vars(CuotaEdad), 
             scales = "free_x", space = "free_x", 
             switch = "y") +
  scale_y_continuous(expand = c(0, 0)) +
  scale_fill_manual(values = c("No" = "#d31919", "Sí" = "#48b150")) +
  labs(
    x     = "Tamaño de municipio",
    y     = "Porcentaje dentro de la celda",
    fill  = "Showrooming",
    title = "Showrooming por Género, Edad y Tamaño de municipio\n(anchura proporcional al tamaño muestral)"
  ) +
  theme_minimal() +
  theme(
    axis.text.x        = element_text(angle = 45, hjust = 1),
    strip.placement    = "outside",
    strip.background.x = element_blank(),
    strip.background.y = element_blank(),
    strip.text.x       = element_text(face = "bold"),
    strip.text.y.left  = element_text(face = "bold", angle = 0),
    panel.grid.major.x = element_blank()
  )

```


## Distribución Escalas Likert

```{r}
niveles <- c(
  "Total en desacuerdo",
  "Muy en desacuerdo",
  "En desacuerdo",
  "Ni de acuerdo ni en desacuerdo",
  "De acuerdo",
  "Muy de acuerdo",
  "Total de acuerdo"
)

to_factor_block <- function(cols) {
  lapply(df_clean[ , cols], function(x)
    factor(x, levels = 1:7, labels = niveles, ordered = TRUE)
  )
}

P6_fact <- as.data.frame(to_factor_block(c("P6_1","P6_2","P6_3")))
P7_fact <- as.data.frame(to_factor_block(c("P7_1","P7_2","P7_3","P7_4")))
P8_fact <- as.data.frame(to_factor_block(c("P8_1","P8_2","P8_3")))

all_items <- likert(cbind(P6_fact, P7_fact, P8_fact))

plot(all_items,
     group.order = c(
       "P6_1", "P6_2", "P6_3",
       "P7_1", "P7_2", "P7_3", "P7_4",
       "P8_1", "P8_2", "P8_3"
     )
) + 
  ggtitle("Distribución respuestas: P6, P6 y P7")
```



# PROPIEDADES PSICOMETRICAS

## Realismo escenario

### Levene's Test (homogeneidad de varianzas)

```{r}
leveneTest(P4 ~ Escenario, data = df_clean)
```

### ANOVA unifactorial

```{r}
aov_p4 <- aov(P4 ~ Escenario, data = df_clean)
summary(aov_p4)
```

### Diagnóstico residuos

```{r}
par(mfrow = c(2,2))
plot(aov_p4)
```

### Comparaciones post-hoc (Tukey)

```{r}
emmeans(aov_p4, "Escenario") %>%
  contrast(method = "pairwise", adjust = "tukey")
```


## Chequeo de confianza percibida

```{r}
# 1 Construir tabla de contingencia
tab_conf <- table(df_clean$Escenario, df_clean$P5_1,
                  dnn = c("Escenario", "Percibió confianza"))

# 2 Ver tabla observada
print(tab_conf)

# 3 Test X^2
chisq_conf <- chisq.test(tab_conf, correct = FALSE)
chisq_conf

# 4 Tabla de frecuencias esperadas
chisq_conf$expected

# 5 Residuos estandarizados
round(chisq_conf$stdres, 2)
```

## Chequeo de servicio percibido

```{r}
# 1 Construir tabla de contingencia
tab_serv <- table(df_clean$Escenario, df_clean$P5_2,
                  dnn = c("Escenario", "Percibió servicio"))

# 2 Ver tabla observada
print(tab_serv)

# 3 Test X2
chisq_serv <- chisq.test(tab_serv, correct = FALSE)
chisq_serv

# 4 Tabla de frecuencias esperadas
chisq_serv$expected

# 5 Residuos estandarizados
round(chisq_serv$stdres, 2)
```

## Análisis Factorial Confirmatorio y propiedades psiconometricas
### Definición del modelo de medida
```{r}
modelo_cfa <- '
  # 1) Definición de los factores latentes y sus indicadores
  GratInmed  =~ 1*P6_1 + P6_2 + P6_3
  Precio     =~ 1*P7_1 + P7_2 + P7_3 + P7_4
  MalaConsc  =~ 1*P8_1 + P8_2 + P8_3

  # 2) Liberar las covarianzas entre los tres factores
  GratInmed ~~ Precio
  GratInmed ~~ MalaConsc
  Precio    ~~ MalaConsc
'
```

### Estimación del CFA

```{r}
# 1) Ajuste del CFA
fit <- cfa(
  model     = modelo_cfa,
  data      = df_clean,  
  std.lv    = FALSE,           # escalamos fijando cargas, no varianza latente
  estimator = "MLM"            # ML robusto
)

# 2) Resumen con medidas de ajuste y estandarizados
summary(fit,
        fit.measures = TRUE,
        standardized = TRUE)

```

### Valoración de la validez y fiabilidad del instrumento de medida

#### Fiabilidad individual: Alpha de Cronbach

```{r}
reliability(fit)[1,]
```
#### Fiabilidad compuesta (CR)
```{r}
reliability(fit)[4,]
```
#### Validez convergente (AVE)

```{r}
reliability(fit)[5,]
```

#### Validez discriminante

```{r}
lavInspect(fit, what="cor.lv")^2
htmt(modelo_cfa, df_clean)
```

# ANÁLISIS EXPLORATORIO

## Estadísticos descriptivos y matriz de correlaciones

```{r}
# 1 Crear composites con nombres explícitos
df_clean <- df_clean %>%
  mutate(
    gratificacion    = rowMeans(select(., P6_1:P6_3), na.rm = TRUE),
    orient_precio    = rowMeans(select(., P7_1:P7_4), na.rm = TRUE),
    culpa            = rowMeans(select(., P8_1:P8_3), na.rm = TRUE)
  )

# 2 Recodificar variables de manipulación
df_clean <- df_clean %>%
  mutate(
    confianza_bin = if_else(ESCENARIO %in% c(2,4), 1, 0),
    servicio_bin  = if_else(ESCENARIO %in% c(3,4), 1, 0)
  )

# 3. Estadísticos descriptivos
est <- describe(df_clean %>% 
           select(confianza_bin, servicio_bin, gratificacion, orient_precio, culpa))

# 4. Matriz de correlaciones (punto-biserial para binarios y Pearson para continuos)
#    Tratamos los binarios como numéricos 0/1
vars_modelo <- c("confianza_bin", "servicio_bin", 
                 "gratificacion", "orient_precio", "culpa")
cor_mat <- df_clean %>% 
  select(all_of(vars_modelo)) %>% 
  cor(use = "pairwise.complete.obs", method = "pearson")

print(cor_mat)

# 5. Significancia de correlaciones
corr.test(
  df_clean %>% select(all_of(vars_modelo)),
  use    = "pairwise",
  method = "pearson",
  adjust = "none"
)

```
### Mapa de calor y matriz de dispersión

```{r}
# Mapa de calor
corr_long <- melt(
  cor_mat,
  varnames   = c("x", "y"),
  value.name = "r"
)

# 6.2 Dibujar
ggplot(corr_long, aes(x = x, y = y, fill = r)) +
  geom_tile(color = "white") +
  scale_fill_distiller(
    palette = "RdBu",
    limit   = c(-1, 1),
    name    = "Correlación"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    panel.grid  = element_blank()
  ) +
  labs(
    x         = NULL,
    y         = NULL,
    title     = "Mapa de calor de correlaciones",
    subtitle  = "Variables predictoras para regresión logística"
  )
```


```{r}
# Matriz de dispersión

# Matriz completa (incluyendo los binarios)
ggpairs(
  df_clean[, vars_modelo],
  upper = list(continuous = wrap("cor", size = 3)),
  lower = list(continuous = "points"),
  diag  = list(continuous = "barDiag")
  ) +
  ggtitle("Matriz de dispersión completa de predictores")

# Solo continuas
ggpairs(
  df_clean[, c("gratificacion", "orient_precio", "culpa")],
  upper = list(continuous = wrap("cor", size = 3)),
  lower = list(continuous = "smooth"),
  diag  = list(continuous = "densityDiag")
) +
  ggtitle("Matriz de dispersión de las escalas continuas")

```


```{r}
ggpairs(
  df_clean[, c("gratificacion", "orient_precio", "culpa")],
  mapping = aes(color = df_clean$S2, alpha=0.08),     
  upper   = list(continuous = wrap("cor", size = 3)),
  lower   = list(continuous = "smooth"),
  diag    = list(continuous = "densityDiag")
) +
  ggtitle("Dispersión de escalas continuas, coloreado por Sexo")

ggpairs(
  df_clean[, c("gratificacion", "orient_precio", "culpa")],
  mapping = aes(color = df_clean$CuotaEdad, alpha=0.08),     
  upper   = list(continuous = wrap("cor", size = 3)),
  lower   = list(continuous = "smooth"),
  diag    = list(continuous = "densityDiag")
) +
  ggtitle("Dispersión de escalas continuas, coloreado por Edad")

ggpairs(
  df_clean[, c("gratificacion", "orient_precio", "culpa")],
  mapping = aes(color = df_clean$TamPob, alpha=0.08),     
  upper   = list(continuous = wrap("cor", size = 3)),
  lower   = list(continuous = "smooth"),
  diag    = list(continuous = "densityDiag")
) +
  ggtitle("Dispersión de escalas continuas, coloreado por Tamaño municipio")

```


# MODELO DE REGRESIÓN LOGÍSTICA
## Modelo inicial: sólo las cinco variables clave
```{r}
modelo_base <- glm(
  SHOWROOMING ~ confianza_bin + servicio_bin +
                gratificacion + orient_precio + culpa,
  data   = df_clean,
  family = binomial(link = "logit")
)
summary(modelo_base)
AIC(modelo_base)
```

## Ampliar con variables sociodemográficas
```{r}
modelo_demo <- update(
  modelo_base,
  . ~ . + CuotaEdad + S2 + TamPob
)
summary(modelo_demo)
AIC(modelo_demo)
anova(modelo_base, modelo_demo, test = "Chisq")
```


## Probar interacciones entre variables clave y demográficas
```{r}
#    - orient_precio x CuotaEdad
#    - gratificacion x TamPob
#    - orient_precio x S2

mod_int_op_age <- update(modelo_demo, . ~ . + orient_precio:CuotaEdad)
mod_int_gra_mun <- update(modelo_demo, . ~ . + gratificacion:TamPob)
mod_int_op_sex <- update(modelo_demo, . ~ . + orient_precio:S2)

# Comparar AIC y pruebas Chi-cuadrado
modelos_demo_int <- list(
  demo       = modelo_demo,
  op_x_age   = mod_int_op_age,
  gra_x_mun  = mod_int_gra_mun,
  op_x_sex   = mod_int_op_sex
)
sapply(modelos_demo_int, AIC)
anova(modelo_demo, mod_int_op_age, test = "Chisq")
anova(modelo_demo, mod_int_gra_mun, test = "Chisq")
anova(modelo_demo, mod_int_op_sex, test = "Chisq")
```

## Probar interacciones entre variables clave
```{r}
#    - confianza_bin x culpa
#    - servicio_bin x orient_precio
#    - servicio_bin x gratificacion
#    - gratificacion x orient_precio
#    - orient_precio x culpa
mod_int_conf_culp <- update(modelo_demo, . ~ . + confianza_bin:culpa)
mod_int_serv_prec <- update(modelo_demo, . ~ . + servicio_bin:orient_precio)
mod_int_serv_gra  <- update(modelo_demo, . ~ . + servicio_bin:gratificacion)
mod_int_gra_prec  <- update(modelo_demo, . ~ . + gratificacion:orient_precio)
mod_int_prec_culp <- update(modelo_demo, . ~ . + orient_precio:culpa)

# Comparar AIC y Chi-cuadrado
modelos_key_int <- list(
  demo            = modelo_demo,
  conf_x_culp     = mod_int_conf_culp,
  serv_x_prec     = mod_int_serv_prec,
  serv_x_gra      = mod_int_serv_gra,
  gra_x_prec      = mod_int_gra_prec,
  prec_x_culp     = mod_int_prec_culp
)
sapply(modelos_key_int, AIC)
anova(modelo_demo, mod_int_conf_culp, test = "Chisq")
anova(modelo_demo, mod_int_serv_prec,  test = "Chisq")
anova(modelo_demo, mod_int_serv_gra,   test = "Chisq")
anova(modelo_demo, mod_int_gra_prec,   test = "Chisq")
anova(modelo_demo, mod_int_prec_culp,  test = "Chisq")

```
## Modelo Final
```{r}
modelo_final <- glm(
  SHOWROOMING ~ confianza_bin + servicio_bin +
                gratificacion + orient_precio + culpa +
                CuotaEdad + S2 + TamPob +
                orient_precio:CuotaEdad +
                gratificacion:TamPob +
                orient_precio:S2,
  family = binomial(link="logit"),
  data   = df_clean
)

summary(modelo_final)

```

# BONDAD DEL AJUSTE DEL MODELO FINAL

```{r}
# 1) Obtener probabilidades y vector 0/1
df_clean$prob_final <- predict(modelo_final, type = "response")
df_clean$show_bin_num <- ifelse(df_clean$SHOWROOMING == "Sí", 1, 0)

# 2) Curva ROC y AUC 
library(pROC)
roc_obj <- roc(
  response = df_clean$show_bin_num,
  predictor = df_clean$prob_final
)
plot(roc_obj, col  = "blue", 
  lwd  = 2,
  main = paste0(
    "Curva ROC del modelo final (AUC = ",
    round(auc(roc_obj), 3),
    ")"
  )
)
auc_val <- auc(roc_obj)

cat("AUC =", round(auc_val, 4), "\n")

# 3) Hosmer–Lemeshow goodness-of-fit
hl <- hoslem.test(
  x = df_clean$show_bin_num,
  y = df_clean$prob_final,
  g = 10
)
print(hl)

# 4) Matriz de confusión
# Definir clase predicha con umbral 0.5
df_clean$pred_class <- factor(
  ifelse(df_clean$prob_final >= 0.5, "Sí", "No"),
  levels = c("No","Sí")
)
CrossTable(
  x         = df_clean$show_bin_num,
  y         = df_clean$pred_class,
  prop.chisq= FALSE,
  prop.t    = FALSE,
  prop.r    = FALSE,
  dnn       = c("Actual","Predicho")
)

# 5) Métricas (accuracy, recall, precision, F1)
cm <- table(
  Actual   = df_clean$show_bin_num,
  Predicho = ifelse(df_clean$pred_class=="Sí", 1, 0)
)
TN <- cm["0","0"]; FP <- cm["0","1"]
FN <- cm["1","0"]; TP <- cm["1","1"]

accuracy    <- (TP + TN) / sum(cm)
sensitivity <- TP / (TP + FN)
specificity <- TN / (TN + FP)
precision   <- TP / (TP + FP)
f1_score    <- 2 * precision * sensitivity / (precision + sensitivity)

metrics <- data.frame(
  Metric        = c("Accuracy","Sensitivity","Specificity","Precision","F1 Score"),
  Value         = c(accuracy, sensitivity, specificity, precision, f1_score)
)
print(metrics)

```
# INTERPRETACIÓN DE RESULTADOS
## Global
```{r}
# 1) Lista de continuas
vars_cont <- c("gratificacion", "orient_precio", "culpa")

# 2) Probabilidades base
p_base <- predict(modelo_final, type = "response")

# 3) Para cada variable, subimos en +1 y computamos p2
ame_cont <- sapply(vars_cont, function(var){
  newdata <- df_clean
  newdata[[var]] <- newdata[[var]] + 1
  p2 <- predict(modelo_final, newdata = newdata, type = "response")
  mean(p2 - p_base)
})

ame_cont

```

```{r}
vars_bin <- c("confianza_bin","servicio_bin")

ame_bin <- sapply(vars_bin, function(var){
  new1 <- df_clean; new1[[var]] <- 1
  new0 <- df_clean; new0[[var]] <- 0
  p1 <- predict(modelo_final, newdata = new1, type = "response")
  p0 <- predict(modelo_final, newdata = new0, type = "response")
  mean(p1 - p0)
})

ame_bin

```

```{r}
df_global <- tibble(
  predictor = c(names(ame_cont), names(ame_bin)),
  ame       = c(ame_cont, ame_bin)
)

ggplot(df_global, aes(x = reorder(predictor, ame), y = ame)) +
  geom_col(alpha = 0.8) +
  coord_flip() +
  labs(
    title = "AME globales de los predictores",
    x     = "Predictor",
    y     = "Cambio medio en p(showrooming)"
  ) +
  theme_minimal()
```

## Orientación al precio x Grupo de edad
```{r}
niv_edad <- levels(df_clean$CuotaEdad)
ame_op_by_age <- sapply(niv_edad, function(lv){
  sub <- df_clean; sub <- sub[sub$CuotaEdad == lv, ]
  p0 <- predict(modelo_final, newdata = sub, type = "response")
  sub2 <- sub; sub2$orient_precio <- sub2$orient_precio + 1
  p1 <- predict(modelo_final, newdata = sub2, type = "response")
  mean(p1 - p0)
})
ame_op_by_age

# Orient_precio x Edad
df_op_age <- tibble(
  CuotaEdad = niv_edad,
  ame        = ame_op_by_age
)

ggplot(df_op_age, aes(x = CuotaEdad, y = ame))  +
  geom_col(alpha = 0.8) +
  coord_flip() +
  labs(
    title = "AME de orient_precio según grupo de edad",
    x     = "Grupo de edad",
    y     = "Var p(showrooming) por +1 orient_precio"
  ) +
  theme_minimal()

```

## Gratificación x Tamaño de municipio
```{r}
mun_counts <- table(df_clean$TamPob)
niveles_presentes <- names(mun_counts)[mun_counts > 0]
ame_gr_by_mun <- sapply(niveles_presentes, function(lv) {
  sub0 <- df_clean[df_clean$TamPob == lv, ]
  # Probabilidad base
  p0 <- predict(modelo_final, newdata = sub0, type = "response")
  # Subimos gratificación en +1 y predecimos de nuevo
  sub1 <- sub0
  sub1$gratificacion <- sub1$gratificacion + 1
  p1 <- predict(modelo_final, newdata = sub1, type = "response")
  # AME para ese nivel
  mean(p1 - p0)
})

ame_gr_by_mun

df_gr_mun <- tibble(
  TamPob = niveles_presentes,
  ame    = ame_gr_by_mun
)

ggplot(df_gr_mun, aes(x = TamPob, y = ame)) +
  geom_col(alpha = 0.8) +
  coord_flip() +
  labs(
    title = "AME de gratificación por tamaño de municipio",
    x     = "Tamaño de Municipio",
    y     = "Var p(showrooming) por +1 gratificación"
  ) +
  theme_minimal()
```
## Orientación al precio x Sexo
```{r}
niv_sex <- levels(df_clean$S2)
ame_op_by_sex <- sapply(niv_sex, function(lv){
  sub <- df_clean; sub <- sub[sub$S2 == lv, ]
  p0 <- predict(modelo_final, newdata = sub, type = "response")
  sub2 <- sub; sub2$orient_precio <- sub2$orient_precio + 1
  p1 <- predict(modelo_final, newdata = sub2, type = "response")
  mean(p1 - p0)
})
ame_op_by_sex

# Orient_precio x Sexo
df_op_sex <- tibble(
  Sexo = niv_sex,
  ame  = ame_op_by_sex
)

ggplot(df_op_sex, aes(x = Sexo, y = ame)) +
  geom_col(alpha = 0.8) +
  coord_flip() +
  labs(
    title = "AME de orient_precio según sexo",
    x     = "Sexo",
    y     = "Var p(showrooming) por +1 orient_precio"
  ) +
  theme_minimal()

```

